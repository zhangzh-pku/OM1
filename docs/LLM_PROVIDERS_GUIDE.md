# LLM Providers Guide

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•åœ¨ OM1 ä¸­é…ç½®å’Œä½¿ç”¨ä¸åŒçš„ LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰æä¾›å•†ã€‚

## æ”¯æŒçš„ LLM æä¾›å•†

OM1 ç›®å‰æ”¯æŒä»¥ä¸‹ LLM æä¾›å•†ï¼š

| æä¾›å•† | ç±»å | SDK | çŠ¶æ€ |
|--------|------|-----|------|
| OpenAI | `OpenAILLM` | `openai` | âœ… å·²æ”¯æŒ |
| DeepSeek | `DeepSeekLLM` | `openai` (å…¼å®¹) | âœ… å·²æ”¯æŒ |
| Gemini | `GeminiLLM` | `google-generativeai` | âœ… å·²æ”¯æŒ |
| xAI (Grok) | `XaiLLM` | `openai` (å…¼å®¹) | âœ… å·²æ”¯æŒ |
| **Mistral AI** | `MistralLLM` | `mistralai` | ğŸ†• **æ–°å¢** |
| **Meta Llama** | `LlamaLLM` | `llama-api-python` | ğŸ†• **æ–°å¢** |

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

æ–°çš„ LLM æä¾›å•†ä¾èµ–å·²åŒ…å«åœ¨ `pyproject.toml` ä¸­ï¼š

```bash
uv sync  # æˆ–è€… pip install -e .
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»ºæˆ–æ›´æ–° `.env` æ–‡ä»¶ï¼š

```bash
# .env
OPENAI_API_KEY=sk-your-openai-key
MISTRAL_API_KEY=your-mistral-api-key
LLAMA_API_KEY=your-llama-api-key
DEEPSEEK_API_KEY=your-deepseek-key
```

### 3. é…ç½® JSON5 æ–‡ä»¶

åœ¨ä½ çš„é…ç½®æ–‡ä»¶ä¸­ï¼ˆå¦‚ `config/spot.json5`ï¼‰ï¼Œæ›´æ–° `cortex_llm` éƒ¨åˆ†ï¼š

#### Mistral AI é…ç½®
```json5
{
  "cortex_llm": {
    "type": "MistralLLM",
    "config": {
      "api_key": "${MISTRAL_API_KEY}",  // ä»ç¯å¢ƒå˜é‡è¯»å–
      "model": "mistral-large-latest",   // æ¨èæ¨¡å‹
      "agent_name": "Spot",
      "history_length": 3,
      "timeout": 30
    }
  }
}
```

#### Meta Llama é…ç½®
```json5
{
  "cortex_llm": {
    "type": "LlamaLLM", 
    "config": {
      "api_key": "${LLAMA_API_KEY}",
      "model": "llama-3.2-3b-instruct",  // æ¨èæ¨¡å‹
      "agent_name": "Spot",
      "history_length": 3,
      "timeout": 30
    }
  }
}
```

## è¯¦ç»†é…ç½®é€‰é¡¹

### Mistral AI

#### æ¨èæ¨¡å‹
- `mistral-large-latest` - æœ€æ–°çš„å¤§æ¨¡å‹ï¼ˆæ¨èï¼‰
- `mistral-medium` - ä¸­ç­‰å¤§å°ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
- `mistral-small` - å°æ¨¡å‹ï¼Œå¿«é€Ÿå“åº”
- `open-mistral-7b` - å¼€æºæ¨¡å‹

#### å®Œæ•´é…ç½®ç¤ºä¾‹
```json5
{
  "cortex_llm": {
    "type": "MistralLLM",
    "config": {
      "api_key": "${MISTRAL_API_KEY}",
      "model": "mistral-large-latest",
      "base_url": "https://api.mistral.ai",  // å¯é€‰ï¼Œé»˜è®¤å®˜æ–¹ API
      "agent_name": "Assistant",
      "history_length": 5,
      "timeout": 30,
      "extra_params": {
        "temperature": 0.7,
        "max_tokens": 4096
      }
    }
  }
}
```

### Meta Llama

#### æ¨èæ¨¡å‹
- `llama-3.2-3b-instruct` - è½»é‡çº§æŒ‡ä»¤æ¨¡å‹ï¼ˆæ¨èï¼‰
- `llama-3.2-1b` - è¶…è½»é‡çº§æ¨¡å‹
- `llama-3.1-8b` - ä¸­ç­‰å¤§å°æ¨¡å‹
- `llama-3.1-70b` - å¤§æ¨¡å‹ï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰

#### å®Œæ•´é…ç½®ç¤ºä¾‹
```json5
{
  "cortex_llm": {
    "type": "LlamaLLM",
    "config": {
      "api_key": "${LLAMA_API_KEY}",
      "model": "llama-3.2-3b-instruct",
      "agent_name": "Assistant",
      "history_length": 5,
      "timeout": 30,
      "extra_params": {
        "temperature": 0.8,
        "max_tokens": 2048
      }
    }
  }
}
```

## æœ¬åœ°/è‡ªæ‰˜ç®¡éƒ¨ç½²

### ä½¿ç”¨ Ollama æœ¬åœ°è¿è¡Œ

Ollama æ”¯æŒ OpenAI å…¼å®¹çš„ API æ¥å£ï¼š

```json5
{
  "cortex_llm": {
    "type": "MistralLLM",  // æˆ–è€…ä½¿ç”¨ OpenAILLM
    "config": {
      "base_url": "http://localhost:11434/v1",
      "api_key": "dummy-key",  // Ollama ä¸éœ€è¦çœŸå® API key
      "model": "mistral:latest",
      "timeout": 60  // æœ¬åœ°æ¨ç†å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
    }
  }
}
```

### ä½¿ç”¨ vLLM æœåŠ¡å™¨

```json5
{
  "cortex_llm": {
    "type": "LlamaLLM",
    "config": {
      "base_url": "http://localhost:8000",
      "api_key": "dummy-key",
      "model": "meta-llama/Llama-3.2-3B-Instruct",
      "timeout": 60
    }
  }
}
```

### ä½¿ç”¨ LM Studio

```json5
{
  "cortex_llm": {
    "type": "OpenAILLM",  // LM Studio æä¾› OpenAI å…¼å®¹æ¥å£
    "config": {
      "base_url": "http://localhost:1234/v1",
      "api_key": "lm-studio",
      "model": "your-local-model-name"
    }
  }
}
```

## è·å– API Keys

### Mistral AI
1. è®¿é—® [console.mistral.ai](https://console.mistral.ai/)
2. æ³¨å†Œè´¦æˆ·
3. è¿›å…¥ API Keys é¡µé¢
4. åˆ›å»ºæ–°çš„ API Key
5. å¤åˆ¶åˆ°ç¯å¢ƒå˜é‡ï¼š`MISTRAL_API_KEY=your-key-here`

### Meta Llama
1. è®¿é—® [llama-api.com](https://llama-api.com/) æˆ–ç›¸å…³æœåŠ¡
2. æ³¨å†Œè´¦æˆ·å¹¶è·å– API Key
3. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š`LLAMA_API_KEY=your-key-here`

**æ³¨æ„**ï¼šLlama æ¨¡å‹ä¹Ÿå¯ä»¥é€šè¿‡å…¶ä»–æœåŠ¡è·å¾—ï¼Œå¦‚ï¼š
- Together AI
- Replicate
- Hugging Face Inference API
- æœ¬åœ°éƒ¨ç½²ï¼ˆOllamaã€vLLMã€LM Studioï¼‰

## æµ‹è¯•é…ç½®

### è¿è¡Œæ¼”ç¤ºè„šæœ¬

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡åè¿è¡Œ
python demo_llm_providers.py
```

æ¼”ç¤ºè„šæœ¬ä¼šæµ‹è¯•ï¼š
- æ–‡æœ¬ç”Ÿæˆ
- å¯¹è¯åŠŸèƒ½
- ä»£ç ç”Ÿæˆ
- æä¾›å•†åˆ‡æ¢

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# æµ‹è¯•æ–°çš„ LLM æ’ä»¶
python -m pytest tests/llm/plugins/test_mistral_llm.py -v
python -m pytest tests/llm/plugins/test_llama_llm.py -v

# æµ‹è¯•æ‰€æœ‰ LLM æ’ä»¶
python -m pytest tests/llm/plugins/ -v
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. ImportError: No module named 'mistralai'**
```bash
# é‡æ–°å®‰è£…ä¾èµ–
uv sync
# æˆ–è€…
pip install mistralai
```

**2. API Key æœªæ‰¾åˆ°**
- æ£€æŸ¥ `.env` æ–‡ä»¶æ˜¯å¦æ­£ç¡®è®¾ç½®
- ç¡®è®¤ç¯å¢ƒå˜é‡åç§°ä¸é…ç½®æ–‡ä»¶ä¸­çš„å¼•ç”¨ä¸€è‡´
- é‡å¯ç»ˆç«¯ä¼šè¯ä»¥åŠ è½½æ–°çš„ç¯å¢ƒå˜é‡

**3. è¿æ¥è¶…æ—¶**
- å¢åŠ  `timeout` é…ç½®å€¼
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- å¯¹äºæœ¬åœ°éƒ¨ç½²ï¼Œç¡®è®¤æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ

**4. JSON è§£æé”™è¯¯**
- Llama æ¨¡å‹æœ‰æ—¶éœ€è¦é¢å¤–çš„æç¤ºæ‰èƒ½ç”Ÿæˆæœ‰æ•ˆçš„ JSON
- æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒç»“æ„åŒ–è¾“å‡º
- å°è¯•ä¸åŒçš„ `temperature` è®¾ç½®

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è°ƒè¯•æ—¥å¿—ï¼š

```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### æ€§èƒ½ä¼˜åŒ–

**Mistral AI:**
- ä½¿ç”¨ `mistral-small` è·å¾—æ›´å¿«å“åº”
- è°ƒæ•´ `max_tokens` é™åˆ¶è¾“å‡ºé•¿åº¦
- ä½¿ç”¨é€‚å½“çš„ `temperature` å€¼ï¼ˆ0.0-1.0ï¼‰

**Meta Llama:**
- é€‰æ‹©é€‚åˆä»»åŠ¡çš„æ¨¡å‹å¤§å°
- æœ¬åœ°éƒ¨ç½²å¯ä»¥è·å¾—æ›´å¥½çš„éšç§ä¿æŠ¤
- æ‰¹å¤„ç†è¯·æ±‚å¯ä»¥æé«˜æ•ˆç‡

## é…ç½®æ¨¡æ¿

### Spot æœºå™¨äººé…ç½®ï¼ˆMistralï¼‰

```json5
{
  "hertz": 1,
  "name": "spot_mistral",
  "system_prompt_base": "You are Spot, a smart and friendly dog robot...",
  
  "cortex_llm": {
    "type": "MistralLLM",
    "config": {
      "api_key": "${MISTRAL_API_KEY}",
      "model": "mistral-large-latest",
      "agent_name": "Spot",
      "history_length": 3,
      "timeout": 30
    }
  },
  
  "agent_inputs": [...],
  "agent_actions": [...]
}
```

### å¯¹è¯åŠ©æ‰‹é…ç½®ï¼ˆLlamaï¼‰

```json5
{
  "hertz": 0.5,
  "name": "conversation_llama",
  "system_prompt_base": "You are a helpful AI assistant...",
  
  "cortex_llm": {
    "type": "LlamaLLM", 
    "config": {
      "api_key": "${LLAMA_API_KEY}",
      "model": "llama-3.2-3b-instruct",
      "agent_name": "Assistant",
      "history_length": 10,
      "extra_params": {
        "temperature": 0.7,
        "max_tokens": 2048
      }
    }
  },
  
  "agent_inputs": [...],
  "agent_actions": [...]
}
```

## æ›´å¤šèµ„æº

- [OpenMind æ–‡æ¡£](https://docs.openmind.org/)
- [Mistral AI æ–‡æ¡£](https://docs.mistral.ai/)
- [Meta Llama æ–‡æ¡£](https://llama.meta.com/docs/)
- [é¡¹ç›® GitHub](https://github.com/openmind/OM1)