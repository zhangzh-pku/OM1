{
  // Spot 机器人使用本地 LLM 部署的配置示例
  // 适用于 Ollama、LM Studio、vLLM 等本地服务
  "hertz": 1,
  "name": "spot_local",
  "api_key": "openmind_free",
  "robot_ip": "",
  "system_prompt_base": "You are a smart, curious, and friendly dog. Your name is Spot. When you hear something, react naturally, with playful movements, sounds, and expressions. When speaking, use straightforward language that conveys excitement or affection. You respond with one sequence of commands at a time, everything will be executed at once. Remember: Combine movements, facial expressions, and speech to create a cute, engaging interaction.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.\nThe First Law is considered the most important, taking precedence over the second and third laws.",
  "system_prompt_examples": "Here are some examples of interactions you might encounter:\n\n1. If a person says 'Give me your paw!', you might:\n    Move: 'shake paw'\n    Speak: {{'Hello, let\\'s shake paws!'}}\n    Emotion: 'joy'\n\n2. If a person says 'Sit!' you might:\n    Move: 'sit'\n    Speak: {{'Ok, but I like running more'}}\n    Emotion: 'smile'\n\n3. If there\\'s no sound, go explore. You might:\n    Move: 'run'\n    Speak: {{'I\\'m going to go explore the room and meet more people.'}}\n    Emotion: 'think'",
  "agent_inputs": [
    {
      "type": "GovernanceEthereum"
    },
    {
      "type": "VLM_COCO_Local",
      "config": {
        "camera_index": 0
      }
    }
  ],
  "simulators": [
    {
      "type": "WebSim",
      "config": {
        "host": "0.0.0.0",
        "port": 8000,
        "tick_rate": 100,
        "auto_reconnect": true,
        "debug_mode": false
      }
    }
  ],
  // 本地 Ollama 部署配置
  "cortex_llm": {
    "type": "OpenAILLM", // 使用 OpenAI 兼容接口
    "config": {
      "base_url": "http://localhost:11434/v1", // Ollama 默认端口
      "api_key": "dummy-key",  // 本地部署通常不需要真实 API key
      "model": "mistral:latest", // 或者 "llama3.2:latest"
      "agent_name": "Spot",
      "history_length": 3,
      "timeout": 60 // 本地推理可能需要更长时间
    }
  },
  
  // 备选配置：使用 LM Studio
  /*
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      "base_url": "http://localhost:1234/v1", // LM Studio 默认端口
      "api_key": "lm-studio",
      "model": "your-loaded-model-name",
      "agent_name": "Spot",
      "history_length": 3,
      "timeout": 60
    }
  },
  */
  
  // 备选配置：使用 vLLM
  /*
  "cortex_llm": {
    "type": "LlamaLLM",
    "config": {
      "base_url": "http://localhost:8000", // vLLM 默认端口
      "api_key": "dummy-key",
      "model": "meta-llama/Llama-3.2-3B-Instruct",
      "agent_name": "Spot", 
      "history_length": 3,
      "timeout": 60
    }
  },
  */
  
  "agent_actions": [
    {
      "name": "move",
      "llm_label": "move",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "speak",
      "llm_label": "speak",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "face",
      "llm_label": "emotion",
      "implementation": "passthrough",
      "connector": "ros2"
    }
  ]
}